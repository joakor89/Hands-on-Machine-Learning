{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddffda6c",
   "metadata": {},
   "source": [
    "# Training and Deploying TensorFlow Models at Scale\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea15354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Python ≥3.5 is required\n",
    "# import sys\n",
    "# assert sys.version_info >= (3, 5)\n",
    "\n",
    "# # # Is this notebook running on Colab or Kaggle?\n",
    "# # IS_COLAB = \"google.colab\" in sys.modules\n",
    "# # IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# # if IS_COLAB or IS_KAGGLE:\n",
    "# #     !echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list\n",
    "# #     !curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
    "# #     !apt update && apt-get install -y tensorflow-model-server\n",
    "# #     %pip install -q -U tensorflow-serving-api\n",
    "\n",
    "# # Scikit-Learn ≥0.20 is required\n",
    "# import sklearn\n",
    "# assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# # TensorFlow ≥2.0 is required\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# # assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# # if not tf.config.list_physical_devices('GPU'):\n",
    "# #     print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "# #     if IS_COLAB:\n",
    "# #         print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "# #     if IS_KAGGLE:\n",
    "# #         print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# # Common imports\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # to make this notebook's output stable across runs\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "# # To plot pretty figures\n",
    "# %matplotlib inline\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# mpl.rc('axes', labelsize=14)\n",
    "# mpl.rc('xtick', labelsize=12)\n",
    "# mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0267ca",
   "metadata": {},
   "source": [
    "## Deploying TensorFlow models to TensorFlow Serving (TFS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cc4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# X_train_full = X_train_full[..., np.newaxis].astype(np.float32) / 255.\n",
    "# X_test = X_test[..., np.newaxis].astype(np.float32) / 255.\n",
    "# X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "# y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "# X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb587d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
    "#     keras.layers.Dense(100, activation=\"relu\"),\n",
    "#     keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#               optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "#               metrics=[\"accuracy\"])\n",
    "# model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27129006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.round(model.predict(X_new), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbdda726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_version = \"0001\"\n",
    "# model_name = \"my_mnist_model\"\n",
    "# model_path = os.path.join(model_name, model_version)\n",
    "# model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42d4a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# shutil.rmtree(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161c9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.saved_model.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6464f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for root, dirs, files in os.walk(model_name):\n",
    "#     indent = '    ' * root.count(os.sep)\n",
    "#     print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "#     for filename in files:\n",
    "#         print('{}{}'.format(indent + '    ', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de3895ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !saved_model_cli show --dir {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc542fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !saved_model_cli show --dir {model_path} --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b81fb419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !saved_model_cli show --dir {model_path} --tag_set serve \\\n",
    "#                       --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13712f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !saved_model_cli show --dir {model_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ed7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"my_mnist_tests.npy\", X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1da2cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_name = model.input_names[0]\n",
    "# input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8306db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !saved_model_cli run --dir {model_path} --tag_set serve \\\n",
    "#                      --signature_def serving_default    \\\n",
    "#                      --inputs {input_name}=my_mnist_tests.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dba5ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.round([[1.1347984e-04, 1.5187356e-07, 9.7032893e-04, 2.7640699e-03, 3.7826971e-06,\n",
    "#            7.6876910e-05, 3.9140293e-08, 9.9559116e-01, 5.3502394e-05, 4.2665208e-04],\n",
    "#           [8.2443521e-04, 3.5493889e-05, 9.8826385e-01, 7.0466995e-03, 1.2957400e-07,\n",
    "#            2.3389691e-04, 2.5639210e-03, 9.5886099e-10, 1.0314899e-03, 8.7952529e-08],\n",
    "#           [4.4693781e-05, 9.7028232e-01, 9.0526715e-03, 2.2641101e-03, 4.8766597e-04,\n",
    "#            2.8800720e-03, 2.2714981e-03, 8.3753867e-03, 4.0439744e-03, 2.9759688e-04]], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859c491",
   "metadata": {},
   "source": [
    "## TensorFlow Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b5ff969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"MODEL_DIR\"] = os.path.split(os.path.abspath(model_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59899da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash --bg\n",
    "# nohup tensorflow_model_server \\\n",
    "#      --rest_api_port=8501 \\\n",
    "#      --model_name=my_mnist_model \\\n",
    "#      --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89782197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tail server.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3654ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# input_data_json = json.dumps({\n",
    "#     \"signature_name\": \"serving_default\",\n",
    "#     \"instances\": X_new.tolist(),\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86be8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repr(input_data_json)[:1500] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cce42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
    "# response = requests.post(SERVER_URL, data=input_data_json)\n",
    "# response.raise_for_status() # raise an exception in case of error\n",
    "# response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095d683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5012e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_proba = np.array(response[\"predictions\"])\n",
    "# y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a153aed",
   "metadata": {},
   "source": [
    "### Using the gRPC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc05aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
    "\n",
    "# request = PredictRequest()\n",
    "# request.model_spec.name = model_name\n",
    "# request.model_spec.signature_name = \"serving_default\"\n",
    "# input_name = model.input_names[0]\n",
    "# request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import grpc\n",
    "# from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "# channel = grpc.insecure_channel('localhost:8500')\n",
    "# predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "# response = predict_service.Predict(request, timeout=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b04fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f71f68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_name = model.output_names[0]\n",
    "# outputs_proto = response.outputs[output_name]\n",
    "# y_proba = tf.make_ndarray(outputs_proto)\n",
    "# y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e238c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = model.output_names[0]\n",
    "outputs_proto = response.outputs[output_name]\n",
    "shape = [dim.size for dim in outputs_proto.tensor_shape.dim]\n",
    "y_proba = np.array(outputs_proto.float_val).reshape(shape)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e78f5",
   "metadata": {},
   "source": [
    "## Deploying a new model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dafb8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
    "#     keras.layers.Dense(50, activation=\"relu\"),\n",
    "#     keras.layers.Dense(50, activation=\"relu\"),\n",
    "#     keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#               optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "#               metrics=[\"accuracy\"])\n",
    "# history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c05b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_version = \"0002\"\n",
    "# model_name = \"my_mnist_model\"\n",
    "# model_path = os.path.join(model_name, model_version)\n",
    "# model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5aedde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.saved_model.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "449e5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for root, dirs, files in os.walk(model_name):\n",
    "#     indent = '    ' * root.count(os.sep)\n",
    "#     print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "#     for filename in files:\n",
    "#         print('{}{}'.format(indent + '    ', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e4f0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
    "            \n",
    "# response = requests.post(SERVER_URL, data=input_data_json)\n",
    "# response.raise_for_status()\n",
    "# response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4f47f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3591b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_proba = np.array(response[\"predictions\"])\n",
    "# y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f255f766",
   "metadata": {},
   "source": [
    "## Deploy the model to Google Cloud AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee30e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_id = \"onyx-smoke-242003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0bd7420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import googleapiclient.discovery\n",
    "\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"my_service_account_private_key.json\"\n",
    "# model_id = \"my_mnist_model\"\n",
    "# model_path = \"projects/{}/models/{}\".format(project_id, model_id)\n",
    "# model_path += \"/versions/v0001/\" # if you want to run a specific version\n",
    "# ml_resource = googleapiclient.discovery.build(\"ml\", \"v1\").projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9dcd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(X):\n",
    "#     input_data_json = {\"signature_name\": \"serving_default\",\n",
    "#                        \"instances\": X.tolist()}\n",
    "#     request = ml_resource.predict(name=model_path, body=input_data_json)\n",
    "#     response = request.execute()\n",
    "#     if \"error\" in response:\n",
    "#         raise RuntimeError(response[\"error\"])\n",
    "#     return np.array([pred[output_name] for pred in response[\"predictions\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed12fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_probas = predict(X_new)\n",
    "# np.round(Y_probas, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f0ed1",
   "metadata": {},
   "source": [
    "## Using GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f089ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf.test.is_gpu_available() # deprecated\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "286827e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c59b8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b129468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client.device_lib import list_local_devices\n",
    "\n",
    "# devices = list_local_devices()\n",
    "# devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99674e0d",
   "metadata": {},
   "source": [
    "## Distributed Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94f9b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.backend.clear_session()\n",
    "# tf.random.set_seed(42)\n",
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f00bfe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     return keras.models.Sequential([\n",
    "#         keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
    "#                             padding=\"same\", input_shape=[28, 28, 1]),\n",
    "#         keras.layers.MaxPooling2D(pool_size=2),\n",
    "#         keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
    "#                             padding=\"same\"), \n",
    "#         keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
    "#                             padding=\"same\"),\n",
    "#         keras.layers.MaxPooling2D(pool_size=2),\n",
    "#         keras.layers.Flatten(),\n",
    "#         keras.layers.Dense(units=64, activation='relu'),\n",
    "#         keras.layers.Dropout(0.5),\n",
    "#         keras.layers.Dense(units=10, activation='softmax'),\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48474042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 100\n",
    "# model = create_model()\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#               optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "#               metrics=[\"accuracy\"])\n",
    "# model.fit(X_train, y_train, epochs=10,\n",
    "#           validation_data=(X_valid, y_valid), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29199634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.backend.clear_session()\n",
    "# tf.random.set_seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "# distribution = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# # Change the default all-reduce algorithm:\n",
    "# #distribution = tf.distribute.MirroredStrategy(\n",
    "# #    cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "\n",
    "# # Specify the list of GPUs to use:\n",
    "# #distribution = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "# # Use the central storage strategy instead:\n",
    "# #distribution = tf.distribute.experimental.CentralStorageStrategy()\n",
    "\n",
    "# #if IS_COLAB and \"COLAB_TPU_ADDR\" in os.environ:\n",
    "# #  tpu_address = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
    "# #else:\n",
    "# #  tpu_address = \"\"\n",
    "# #resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n",
    "# #tf.config.experimental_connect_to_cluster(resolver)\n",
    "# #tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "# #distribution = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "\n",
    "# with distribution.scope():\n",
    "#     model = create_model()\n",
    "#     model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#                   optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "#                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66f6fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 100 # must be divisible by the number of workers\n",
    "# model.fit(X_train, y_train, epochs=10,\n",
    "#           validation_data=(X_valid, y_valid), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f158abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61b00722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.backend.clear_session()\n",
    "# tf.random.set_seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "# K = keras.backend\n",
    "\n",
    "# distribution = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# with distribution.scope():\n",
    "#     model = create_model()\n",
    "#     optimizer = keras.optimizers.SGD()\n",
    "\n",
    "# with distribution.scope():\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).repeat().batch(batch_size)\n",
    "#     input_iterator = distribution.make_dataset_iterator(dataset)\n",
    "    \n",
    "# @tf.function\n",
    "# def train_step():\n",
    "#     def step_fn(inputs):\n",
    "#         X, y = inputs\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             Y_proba = model(X)\n",
    "#             loss = K.sum(keras.losses.sparse_categorical_crossentropy(y, Y_proba)) / batch_size\n",
    "\n",
    "#         grads = tape.gradient(loss, model.trainable_variables)\n",
    "#         optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "#         return loss\n",
    "\n",
    "#     per_replica_losses = distribution.experimental_run(step_fn, input_iterator)\n",
    "#     mean_loss = distribution.reduce(tf.distribute.ReduceOp.SUM,\n",
    "#                                     per_replica_losses, axis=None)\n",
    "#     return mean_loss\n",
    "\n",
    "# n_epochs = 10\n",
    "# with distribution.scope():\n",
    "#     input_iterator.initialize()\n",
    "#     for epoch in range(n_epochs):\n",
    "#         print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
    "#         for iteration in range(len(X_train) // batch_size):\n",
    "#             print(\"\\rLoss: {:.3f}\".format(train_step().numpy()), end=\"\")\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad0d275",
   "metadata": {},
   "source": [
    "## Training across multiple servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a29150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_spec = {\n",
    "#     \"worker\": [\n",
    "#         \"machine-a.example.com:2222\",  # /job:worker/task:0\n",
    "#         \"machine-b.example.com:2222\"   # /job:worker/task:1\n",
    "#     ],\n",
    "#     \"ps\": [\"machine-c.example.com:2222\"] # /job:ps/task:0\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2fed2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "\n",
    "# os.environ[\"TF_CONFIG\"] = json.dumps({\n",
    "#     \"cluster\": cluster_spec,\n",
    "#     \"task\": {\"type\": \"worker\", \"index\": 1}\n",
    "# })\n",
    "# os.environ[\"TF_CONFIG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82c7ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
    "# resolver.cluster_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8049bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolver.task_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1183d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolver.task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03d37e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile my_mnist_multiworker_task.py\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import time\n",
    "\n",
    "# # At the beginning of the program\n",
    "# distribution = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "# resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
    "# print(\"Starting task {}{}\".format(resolver.task_type, resolver.task_id))\n",
    "\n",
    "# # Only worker #0 will write checkpoints and log to TensorBoard\n",
    "# if resolver.task_id == 0:\n",
    "#     root_logdir = os.path.join(os.curdir, \"my_mnist_multiworker_logs\")\n",
    "#     run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "#     run_dir = os.path.join(root_logdir, run_id)\n",
    "#     callbacks = [\n",
    "#         keras.callbacks.TensorBoard(run_dir),\n",
    "#         keras.callbacks.ModelCheckpoint(\"my_mnist_multiworker_model.h5\",\n",
    "#                                         save_best_only=True),\n",
    "#     ]\n",
    "# else:\n",
    "#     callbacks = []\n",
    "\n",
    "# # Load and prepare the MNIST dataset\n",
    "# (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# X_train_full = X_train_full[..., np.newaxis] / 255.\n",
    "# X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "# y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# with distribution.scope():\n",
    "#     model = keras.models.Sequential([\n",
    "#         keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
    "#                             padding=\"same\", input_shape=[28, 28, 1]),\n",
    "#         keras.layers.MaxPooling2D(pool_size=2),\n",
    "#         keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
    "#                             padding=\"same\"), \n",
    "#         keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
    "#                             padding=\"same\"),\n",
    "#         keras.layers.MaxPooling2D(pool_size=2),\n",
    "#         keras.layers.Flatten(),\n",
    "#         keras.layers.Dense(units=64, activation='relu'),\n",
    "#         keras.layers.Dropout(0.5),\n",
    "#         keras.layers.Dense(units=10, activation='softmax'),\n",
    "#     ])\n",
    "#     model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#                   optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "#                   metrics=[\"accuracy\"])\n",
    "\n",
    "# model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "#           epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f57b7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0697ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# cluster_spec = {\"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"]}\n",
    "\n",
    "# for index, worker_address in enumerate(cluster_spec[\"worker\"]):\n",
    "#     os.environ[\"TF_CONFIG\"] = json.dumps({\n",
    "#         \"cluster\": cluster_spec,\n",
    "#         \"task\": {\"type\": \"worker\", \"index\": index}\n",
    "#     })\n",
    "#     subprocess.Popen(\"python my_mnist_multiworker_task.py\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5857c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=./my_mnist_multiworker_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1c649f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "\n",
    "# model = keras.models.load_model(\"my_mnist_multiworker_model.h5\")\n",
    "# Y_pred = model.predict(X_new)\n",
    "# np.argmax(Y_pred, axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
